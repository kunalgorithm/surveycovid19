{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data, convert all Excel non-string types to Python strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "converters = {'TimeFinished': str,' On a scale of 1 to 10, how reasonable do you think the public reaction is to COVID-19 now? (1 is under-reacting and 10 is overreacting)':str,'On a scale of 1 to 10, how much do you trust the government to respond to COVID-19 effectively? (1 is strongly distrust and 10 is strongly trust)':str,' Over the past week, have you been continually worried or anxious about a number of events or activities in your daily life?':str,'What is the zip code (i.e. postcal code) of the place you currently live in?':str}\n",
    "data = pd.read_excel('Master.xlsx',sheet_name='Master',converters=converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip spaces from beginning of strings, standardize \"No Response\" as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'O':\n",
    "        data[col] = data[col].str.lstrip()\n",
    "\n",
    "data = data.replace('NR', np.NaN)\n",
    "data = data.replace('Invalid', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize first letter capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['What is your employment status?'] = data['What is your employment status?'].str.capitalize() \n",
    "data['What is your gender?'] = data['What is your gender?'].str.capitalize()\n",
    "data['What is your ethnicity?'] = data['What is your ethnicity?'].str.capitalize() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datetime, Day, Age, Age Group variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Datetime'] = pd.to_datetime(data.TimeFinished)\n",
    "data['Day'] = data['Datetime'].dt.strftime(\"%b-%d\")\n",
    "data['Age'] = 2020 - data['What year were you born?']\n",
    "data['Age Groups'] = pd.cut(x=data['Age'], bins=[0, 24, 39, 54, 70, 100]).apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Variables, (Female,Male,Student,Retired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Female','Male']] = pd.get_dummies(data['What is your gender?'])[['Female','Male']]\n",
    "data[['Student','Retired']] = pd.get_dummies(data['What is your employment status?'])[['Student','Retired']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WFH? column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['In the past 3 days, did you work from home (WFH)?'] = data['In the past 3 days, did you work from home (WFH)?'].str.replace('home on some days','home for some days')\n",
    "data['In the past 3 days, did you work from home (WFH)?'] = data['In the past 3 days, did you work from home (WFH)?'].str.replace('provide an option for me to work from home','provide an option to WFH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomelist = data['What is your annual household income?']\n",
    "incomelist2 = []\n",
    "for x in incomelist:\n",
    "    x1 = str(x)\n",
    "    x1 = x1.replace('Between $150,000 and $199,000','More than $150,000')\n",
    "    x1 = x1.replace('More than $200,000','More than $150,000')\n",
    "    x1 = x1.replace('high_iii','More than $150,000')\n",
    "    x1 = x1.replace('high_ii','Between $125,000 and $149,999')\n",
    "    x1 = x1.replace('high_i','Between $100,000 and $124,999')\n",
    "    x1 = x1.replace('middle_ii','Between $75,000 and $99,999')\n",
    "    x1 = x1.replace('middle_i','Between $50,000 and $74,999')\n",
    "    x1 = x1.replace('lower_ii','Between $25,000 and $49,999')\n",
    "    x1 = x1.replace('lower_i','Less than $25,000')\n",
    "    \n",
    "    x1 = x1.replace('prefer_not_to_say','Prefer not to say')\n",
    "    incomelist2.append(x1)\n",
    "data['income_group'] = incomelist2\n",
    "data['income_group'] = data['income_group'].str.replace('$','$\\$$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethnicity column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ethnicity'] = data['What is your ethnicity?'].str.replace('White','Caucasian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Hispanic/latinx','Hispanic')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Latino','Hispanic')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Hispanic/latinx','Hispanic')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Black/african american','Black')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Caucasian, asian/asian american','Multiracial')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Caucasian, hispanic/latinx','Multiracial')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Asian/asian american','Asian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Caucasian, armenian','Multiracial')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Asian, other','Asian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Caucasian, jewish','Caucasian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Caucasian, asian','Multiracial')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Multiracial/asian american','Multiracial')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Arab','Asian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Asian, pacific islander','Asian')\n",
    "data['Ethnicity'] = data['Ethnicity'].str.replace('Prefer_not_to_say','Prefer not to say')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
